
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5.0, minimum-scale=0.2">


<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <!--
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-09RRKD7CRD"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-09RRKD7CRD');
    </script>
    <script>var clicky_site_ids = clicky_site_ids || []; clicky_site_ids.push(101296995);</script>
    <script async src="//static.getclicky.com/js"></script>    
    -->

    <script>
        // 判断是否为移动端运行环境 

        // if(/AppleWebKit.*Mobile/i.test(navigator.userAgent) || (/MIDP|SymbianOS|NOKIA|SAMSUNG|LG|NEC|TCL|Alcatel|BIRD|DBTEL|Dopod|PHILIPS|HAIER|LENOVO|MOT-|Nokia|SonyEricsson|SIE-|Amoi|ZTE/.test(navigator.userAgent))){ 

        // if(window.location.href.indexOf("?mobile")<0){ 
        try{ 
            // if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)){ 
            if (window.screen.width < 700) {
            // 判断访问环境是 Android|webOS|iPhone|iPod|BlackBerry 则加载以下样式 
                setActiveStyleSheet("jemdoc_mobile.css"); 
            } 
            else if(/iPad/i.test(navigator.userAgent)){ 
            // 判断访问环境是 iPad 则加载以下样式 
                setActiveStyleSheet("jemdoc.css"); 
            } 
            else{ 
            // 判断访问环境是 其他移动设备 则加载以下样式 
                setActiveStyleSheet("jemdoc.css"); 
            } 
        } 
        catch(e){} 
        // } 
        // } 

        // else{ 

        // 如果以上都不是，则加载以下样式 

        // setActiveStyleSheet("jemdoc.css"); 

        // } 

        // 判断完毕后加载样式 

        function setActiveStyleSheet(filename){
            document.write("<link href="+filename+" rel=stylesheet>");
        }
    </script>

    <link rel="shortcut icon" href="myIcon.ico">
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="keywords" content="Yaohai Zhou, UCLA, HUST, 周耀海">
    <meta name="description" content="Yaohai Zhou's home page">
    <!-- <link rel="stylesheet" href="jemdoc.css" type="text/css" />
    <link rel="stylesheet" media="screen and (max-width:700px)" href="jemdoc_mobile.css" type="text/css" />
    <link rel="stylesheet" media="screen and (max-width:700px)" href="jemdoc.css" type="text/css" /> -->
    <title>Yaohai Zhou</title>
</head>

<body>
    <div id="layout-content" style="margin-top:0px">
        <table>
            <tbody>
                <tr>
                    <td width="80%">
                        <div id="toptitle">
                        <h1>Yaohai Zhou (周耀海)</h1>
				        </div>
                        <h3>Master student</h3>
                        <p>
                            Email: <a href="mailto:zyh828482@gmail.com">zyh828482 [at] gmail.com</a>
                        </p>
                        <p>
                            <a href="https://github.com/zyhhhy"><img src="assets/github.png" height="30px"></a>
                        </p>
                        <b>Stay hungry, stay foolish.</b>
                    </td>
			        <td width="20%"><img src="assets/yaohaizhou.jpg" border="0" width="100%"></br></td>
		<tr>
	</tbody>
</table>

<h2>Biography</h2>
<!-- <h2>Biography</h2> -->
<p>
    <div style="text-align:justify"> 
        I am a M.S. candidate with over 4 years of programming experience in various areas, including backend development, cloud & distributed systems, database and machine learning; solid programming skills in Go, Python, C++, and SQL; hands-on experience with Gin, PyTorch and GCP; strong knowledge of algorithms, data structures.
    </div>
</p>
<!-- <p>My research interests lie within Natural Language Processing, particularly in Dialogue System and Vision-Language tasks. I am also involved in Cognitive Science and its application in Dialogue System.</p> -->
<!-- <p><font color="red">Pinned: </font></p> -->
<!-- <h2>News</h2>
<ul>
    <li>
        [2021/07] Talk at the NSF Future Directions Workshop on the Automatic Evaluation of Open-Domain Dialog (AED).
    </li>
    <li>
        [2021/06] Talk at Baidu NLP on pre-training and evaluation for open-domain dialogue.
    </li>
    <li>
        [2021/05] Two papers about dialogue pre-training and dialogue consistency evaluation were accepted to ACL2021.
    </li>
    <li>
        [2021/04] We will organize <a href="https://sites.google.com/dstc.community/dstc10/tracks">Track1: MOD:Internet Meme Incorporated Open-domain Dialog</a> at DSTC10. Welcome to join the challenge!
    </li>
    <li>
        [2021/02] One paper about Audio-Visual Scene-aware Dialogue was accepted to IEEE/ACM TASLP.
    </li>
    <li>
        [2021/02] Our project (Science Fiction AI-Human Co-writing) won the First Prize in the 6th National Youth Artificial Intelligence Innovation, CAAI, advised by Yonggang Wang and Ming Zhou.
    </li>
    <li>
        [2020/11] One paper about Interactive Dialogue System was accepted to DSTC9@AAAI2021.
    </li>
    <li>
        [2020/10] We participated in the DSTC9 Interactive Dialogue Evaluation Track. We tied the 1st in sub-task1 and got the 3rd place in sub-task2.
    </li>
    <li>
        [2020/08] Our project (Science Fiction AI-Human Co-writing) won the 1st place in the Innovation Track at Deecamp 2020.
    </li>
    <li>
        [2019/11] One paper about Audio-Visual Scene-aware Dialogue was accepted to DSTC8@AAAI2020.
    </li>
    <li>
        [2019/10] We won the 1st place in the DSTC8 AVSD Track.
    </li>
    <li>
        [2019/05] One paper about Document Grounded Conversations was accepted to ACL2019.
    </li><li>
        [2018/11] I join WeChat AI as Research Intern.
    </li>
</ul> -->

<h2>Education</h2>
<ul>
    <li>
        <div style="display: flex; justify-content: space-between;">
            <div><a href="https://www.ucla.edu/">University of California Los Angeles (UCLA)</a>, Los Angeles, USA</div>
            <div style="margin-left: 2px;">Sep. 2022 – Dec. 2023 (expected)</div>
        </div>
        Master of Engineering, Artificial Intelligence/Computer Science<br>
    </li>
    <li>
        <div style="display: flex; justify-content: space-between;">
            <div><a href="https://www.hust.edu.cn">Huazhong University of Science and Technology</a>, Wuhan, China</div>
            <div style="margin-left: 2px;">Sep. 2018 – Jun. 2022</div>
        </div>
        Bachelor of Engineering, Electrical and Computer Engineering<br>
    </li>

</ul>

<h2>Experience</h2>
<ul>
	<li>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>PPIO Edge Cloud</div>
            <div style="margin-left: 2px;">Remote</div>
        </div>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Software Engineer Intern · Apus Network: Web3 & AIGC Infrastructure Development</div>
            <div style="margin-left: 2px;">Feb. 2023 – Present</div>
        </div>
        <ul>
            <li>
                Developed <b><a href="https://dazzleai.network/">DazzleAI</a></b>, a plarform in <b>Golang</b> and <b>Gin</b>, enabling <b>Stable-Diffusion</b> image generation and GPU sharing.
            </li>
            <li>
                Implemented backend functionalities, including a message queue (<b>AWS SQS</b>) system, Metamask login, crypto payment.
            </li>
            <li>
                Deployed the Stable-Diffusion service on <b>AWS EC2</b> instances, achieving image generation in an average of 5 seconds.
            </li>
            <li>
                Utilized Docker technology to significantly streamline environment setup and configuration processes for edge cloud machines.
            </li>
            <li>
                Developed a producer-consumer pattern using <b>Node.js</b> to synchronize TOP 100 models on Civitai to the Hugging Face.
            </li>
            <li>
                Trained <b>Stable Diffusion</b> LoRA model for anime character Misaka Mikoto and shared it on civitai platform.
            </li>

        </ul>
	</li>
	<li>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Intel</div>
            <div style="margin-left: 2px;">Beijing, China</div>
        </div>
        <!-- Intel, Beijing, China<br> -->
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Software Engineer Intern · Network Platform Group: AI Channel Link Adaptation</div>
            <div style="margin-left: 2px;">Jul. 2021 – Jan. 2022</div>
        </div>
        <ul>
            <li>
                Developed a pipeline utilizing reinforcement learning to increase the transmission throughput in 5G scenarios.
                <ul>
                    <li>
                        Built the offline data pipeline and the training & testing environment using <b>PyTorch</b>.
                    </li>
                    <li>
                        Used Matlab to simulate ideal wireless transmission scenarios and visualized data relationship using <b>Python</b>.
                    </li>
                    <li>
                        Combined Dueling Double DQN and Time Series Neural Networks to handle multi-frame data.
                    </li>
                    <li>
                        Created an efficient input combination to help the model adapt to the channel changes very quickly.
                    </li>
                    <li>
                        Starting from the principle of link adaptation, used a mathematical trick to accelerate the convergence speed.
                    </li>
                </ul>

            </li>
            <li>
                Converted model to ONNX and deployed the model on Intel’s FlexRAN platform using OneDNN in <b>C/C++</b>.
            </li>
            <li>
                Achieved 10% higher throughput and faster adjustment speed than traditional algorithm.
            </li>
        </ul>
	</li>
	<li>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Shenzhen Innox Academy</div>
            <div style="margin-left: 2px;">Shenzhen, Guangdong province, China</div>
        </div>
        <!-- Shenzhen Innox Academy, Shenzhen, Guangdong province, China<br> -->
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Software Engineer Intern · Auto-Driving Group: 3D Vision Mapping Generation</div>
            <div style="margin-left: 2px;">Feb. 2022 – Apr. 2022</div>
        </div>
        <ul>
            <li>
                Used 2D camera pictures to generate vision maps using Multiple Vision Geometry and Computer Vision techniques.
            </li>
            <li>
                Collect raw images through fisheye cameras, preprocess and extract semantic segmentation result in <b>Python</b> and MM-Detection.
            </li>
            <li>
                Proposed a method to filter straight lines (poles and lights) in maps and corresponding positioning algorithm in <b>tensorRT C++</b>.
            </li>
            <li>
                Deployed the model on a sweeper car and joint debugged with navigation and object detection algorithms.
            </li>
        </ul>
	</li>
	<li>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>HUST Dian Group</div>
            <div style="margin-left: 2px;">Wuhan, China</div>
        </div>
        <!-- Shenzhen Innox Academy, Shenzhen, Guangdong province, China<br> -->
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Software Engineer · AI team: Truck Detection Algorithm for Intelligent Transportation System</div>
            <div style="margin-left: 2px;">Mar. 2021 – Jun. 2021</div>
        </div>
        <ul>
            <li>
                Developed a system to detect trucks (100K pictures per day) in traffic cameras using computer vision techniques.
            </li>
            <li>
                Optimized network of YOLOv5 using <b>PyTorch</b> by model distillation, model fusion, adding attention mechanism.
            </li>
            <li>
                Used <b>TensorRT-C++</b> to deploy the model in a Traffic Department and maintained the system running until now.
            </li>
            <li>
                Achieved 96% accuracy and 93% recall on real truck detection scenario. Earned $30,000 on this project.
            </li>
        </ul>
	</li>
</ul>

<h2>Projects (Selected)</h2>
<ul>
	<li>
        <b>ZIPPAPER: A CHATGPT-BASED PAPER SUMMARY WEB APPLICATION</b><br>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>(Golang, Gin, Vue, MySQL, Python, ChatGPT, GCP VM, AWS S3)</div>
            <div style="margin-left: 2px;">Jan. 2023 – Present</div>
        </div>
        <ul>
            <li>
                Created <a href="https://zippaper.org/">ZipPaper</a>, a web application to automatically generate mindmaps for papers using ChatGPT in <b>Golang</b>, <b>Vue</b>, and <b>Python</b>.
            </li>
            <li>
                Conducted web crawling on Arxiv.org to gather the latest papers and utilized <b>ChatGPT</b> to generate bullet points of the core info.
            </li>
            <li>
                Developed additional backend functionality, including message queue distribution system, Google account login and PDF upload.
            </li>            
            <li>
                Launched on the Internet, built a discord group to collect users’ feedback. Planning to make money.
            </li>
        </ul>
	</li>
	<li>
        <b>
            RAFT-KV DATABASE: A FAULT-TOLERANT KEY/VALUE STORAGE SYSTEM</b><br>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>(Go, RPC, Key/Value Storage System, Multi-threaded programming)</div>
            <div style="margin-left: 2px;">Sep. 2022 – Dec. 2022</div>
        </div>
        <ul>
            <li>
                Supported transactions and commands to Create, Read, Update, and Delete (CRUD) key-value pairs in <b>Go</b>.
            </li>
            <li>
                Adopted Raft consensus protocol for leader election & log replication to ensure consistency and partition tolerance.
            </li>
            <li>
                Introduced atomicity, consistency, isolation, and durability (<b>ACID</b>) by applying Two-Phase Commit.
            </li>
            <li>
                Ran a coordinator daemon to solve deadlock by detecting and breaking the cycle in the directed graph.
            </li>
        </ul>
	</li>
    <li>
        <b>VECTORIZED SIMILARITY SEARCH IN MULTIMODAL DATABASES <a href="http://34.168.201.92:8501/">Demo</a></b><br>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>(Python, Streamlit, PyTorch, KNN, Faiss ANN, GCP)</div>
            <div style="margin-left: 2px;">Sep. 2022 – Dec. 2022</div>
        </div>
        <ul>
            <li>
                Co-designed a multimodal database including texts and images in Python and deployed on <b>GCP</b>.
            </li>
            <li>
                Introduced CLIP to embed texts and images into high-dimensional vector spaces and fine-tune pre-trained model.
            </li>
            <li>
                Implemented kNN and Faiss Approximate Nearest Neighbor (ANN) to conduct multimodal similarity searches.
            </li>
        </ul>
	</li>
    <!-- <li>
        <b>TRUCK DETECTION ALGORITHM FOR INTELLIGENCE TRANSPORTATION SYSTEM</b><br>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>(Python, PyTorch, Ubuntu, C++, Shell)</div>
            <div style="margin-left: 2px;">Mar. 2021 – Jun. 2021</div>
        </div>
        <ul>
            <li>
                Developed a system to detect trucks (100K pictures per day) in traffic cameras using computer vision techniques.
            </li>
            <li>
                Optimized network of YOLOv5 using <b>PyTorch</b> by model distillation, model fusion, adding attention mechanism.
            </li>
            <li>
                Used <b>TensorRT-C++</b> to deploy the model in a Traffic Department and maintained the system running until now.
            </li>
            <li>
                Achieved 96% accuracy and 93% recall on real truck detection scenario. Earned $30,000 on this project.
            </li>
        </ul>
	</li> -->
</ul>

<h2>Honors & Awards</h2>
<ul>
	<!-- <li>
		<div style="float:left; text-align:left">Outstanding Graduate award, Huazhong University of Science and Technology</div> <div style="float:right; text-align:right">Jun. 2020</div>
        
    </li> -->
    <li>
        <div style="display: flex; justify-content: space-between;">
            <div>National Scholarship for China (0.2%)</div>
            <div style="margin-left: 2px;">Oct. 2021</div>
        </div>
    </li>
    <li>
        <div style="display: flex; justify-content: space-between;">
            <div>Finalist in Mathematical Contest in Modeling (2%)</div>
            <div style="margin-left: 2px;">Apr. 2021</div>
        </div>
    </li>
</ul>

<!-- <h2>Publications [<a href="https://scholar.google.com/citations?user=jkcRdBgAAAAJ&hl=en">Google Scholar</a>]</h2> -->
<h2>Publications (Selected)</h2>
<ul>
    <li>
        <a href="https://ieeexplore.ieee.org/document/9666981">Efficient Human Pose Estimation by Maximizing Fusion and High-Level Spatial Attention</a><br>
        Zhiyuan Ren; <b>Yaohai Zhou</b>; Yizhe Chen; Ruisong Zhou; Yayu Gao.<br>
        <em>IEEE International Conference on Automatic Face and Gesture Recognition, 2021 · Jan 12, 2022<br>
    </li>
    <li>
        <a href="https://ieeexplore.ieee.org/document/9625323">Channel Prediction with Liquid Time-Constant Networks: An Online and Adaptive Approach</a><br>
        Hao Yin; <b>Yaohai Zhou</b>; Liu Cao; Yifei Xu<br>
        <em>IEEE 94th Vehicular Technology Conference, 2021 · Dec 10, 2021<br>
    </li>
</ul>

<div id="footer">
	<div id="footer-text" style="text-align: center;">© Yaohai Zhou | Last updated: 02/06/2023</div>
</div>

</div>

</body>
</html>

