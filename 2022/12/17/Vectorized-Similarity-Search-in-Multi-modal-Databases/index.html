<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Vectorized Similarity Search in Multi-modal Databases | Yaohai's Blog</title><meta name="author" content="Yaohai Zhou"><meta name="copyright" content="Yaohai Zhou"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Introduction Github Report Demo(GPU) Demo(CPU) Presentation Slide This is a class project on UCLA CS260 Machine Learning Algorithm advised by Professor Quanquan Gu. We build a multimodal database incl">
<meta property="og:type" content="article">
<meta property="og:title" content="Vectorized Similarity Search in Multi-modal Databases">
<meta property="og:url" content="http://yaohaizhou.com/2022/12/17/Vectorized-Similarity-Search-in-Multi-modal-Databases/index.html">
<meta property="og:site_name" content="Yaohai&#39;s Blog">
<meta property="og:description" content="Introduction Github Report Demo(GPU) Demo(CPU) Presentation Slide This is a class project on UCLA CS260 Machine Learning Algorithm advised by Professor Quanquan Gu. We build a multimodal database incl">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yaohaizhou.com/2022/12/17/Vectorized-Similarity-Search-in-Multi-modal-Databases/db.jpeg">
<meta property="article:published_time" content="2022-12-17T18:30:37.000Z">
<meta property="article:modified_time" content="2023-02-02T05:35:51.653Z">
<meta property="article:author" content="Yaohai Zhou">
<meta property="article:tag" content="Project">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yaohaizhou.com/2022/12/17/Vectorized-Similarity-Search-in-Multi-modal-Databases/db.jpeg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://yaohaizhou.com/2022/12/17/Vectorized-Similarity-Search-in-Multi-modal-Databases/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Vectorized Similarity Search in Multi-modal Databases',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-02-01 21:35:51'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.JPG" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">6</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/2022/12/17/Vectorized-Similarity-Search-in-Multi-modal-Databases/db.jpeg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Yaohai's Blog</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Vectorized Similarity Search in Multi-modal Databases</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-12-17T18:30:37.000Z" title="Created 2022-12-17 10:30:37">2022-12-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-02-02T05:35:51.653Z" title="Updated 2023-02-01 21:35:51">2023-02-01</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Vectorized Similarity Search in Multi-modal Databases"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="introduction">Introduction</h1>
<p><a
target="_blank" rel="noopener" href="https://github.com/zyhhhy/Vectorized-Similarity-Search-in-Multi-modal-Databases">Github</a>
<a
target="_blank" rel="noopener" href="https://github.com/zyhhhy/Vectorized-Similarity-Search-in-Multi-modal-Databases/blob/main/report/Vectorized%20Similarity%20Search%20in%20Multi-modal%20Databases.pdf">Report</a>
<a target="_blank" rel="noopener" href="http://18.237.16.206:8501/">Demo(GPU)</a> <a
target="_blank" rel="noopener" href="http://34.168.201.92:8501/">Demo(CPU)</a> <a
target="_blank" rel="noopener" href="https://github.com/zyhhhy/Vectorized-Similarity-Search-in-Multi-modal-Databases/blob/main/presentation/Final%20Project%20ver2.pptx.pdf">Presentation
Slide</a></p>
<p>This is a class project on UCLA CS260 Machine Learning Algorithm
advised by Professor <a target="_blank" rel="noopener" href="https://web.cs.ucla.edu/~qgu/">Quanquan
Gu</a>.</p>
<p>We build a multimodal database including texts and images, which can
query images by texts, and vice versa. Textual and visual embeddings are
extracted by the techniques of CLIP. kNN and ANN are used as similarity
search strategies. We study the performance of this approach and achieve
achieved 96% precision rate on MS-COCO dataset. Online demo is available
at <a target="_blank" rel="noopener" href="http://18.237.16.206:8501/">Demo(GPU)</a> and <a
target="_blank" rel="noopener" href="http://34.168.201.92:8501/">Demo(CPU)</a>.</p>
<p><img src="flow%20chart.png" /></p>
<h1 id="project-technology">Project Technology</h1>
<p>The project has three major parts of technology, including fecture
embedding, similarity search and user interface.</p>
<h2 id="feature-embedding">Feature Embedding</h2>
<p>We introduce Contrastive Language-Image Pre-training (CLIP) to embed
texts and images into high-dimensional vector spaces and fine-tune
pre-trained model to achieve better performance.</p>
<p>CLIP is a multimodal neural network architecture. It can process two
kinds of input context which are images and their corresponding captions
and gain their high-dimensional vectors. Then CLIP calculates the
similarity between each image embedding vector and text embedding
vector. Because each image has the highest similarity with its own
caption, in the confusion matrix, the values on the diagonal should be
the largest in each row and column. On this setting, CLIP jointly trains
an image encoder and a text encoder to predict the correct pairings of a
batch of (image, text) training samples.</p>
<p><img src="clipmodel.png" /></p>
<h2 id="similarity-search">Similarity Search</h2>
<p>We implement k-Nearest Neighbor (kNN) and Faiss Approximate k-Nearest
Neighbor (ANN) to conduct multimodal similarity searches, which include
image to text, image to image, text to image, and text to text
functions.</p>
<p>Let <span class="math inline">\(q\)</span> be the query vector, and
<span class="math inline">\(\{c_i\}^n_{i=1}\)</span> be the search
candidates. The KNN algorithm ranks <span
class="math inline">\(\{c_i\}^n_{i=1}\)</span> by similarity scores
<span class="math inline">\(\{s(q,c_i)\}^n_{i=1}\)</span> with
descending order and return the first k candidates as final answers.</p>
<p>We utilize Meta Faiss IVF algorithm as our ANN model. To begin with,
it partitions all candidates into m groups and computes the center point
of each group as representative. For each query q, it first computes
similarity scores with m representatives and selects the most similar t
ones. Then, only the candidates within these t groups will be considered
to calculate similarities. Like kNN, the most similar k ones will be
returned.</p>
<h2 id="user-interface">User Interface</h2>
<p>We use an open-source python library Streamlit to construct user
interface. It makes everyone can access to and test our work through web
easily and dynamically.</p>
<p>For more details, you can read our project <a
target="_blank" rel="noopener" href="https://github.com/zyhhhy/Vectorized-Similarity-Search-in-Multi-modal-Databases/blob/main/report/Vectorized%20Similarity%20Search%20in%20Multi-modal%20Databases.pdf">report</a>.
Please feel free to give me more advice for my further development.</p>
<h1 id="implementation-details">Implementation Details</h1>
<p>When we are developing the user interface, we come accoss many
problems.</p>
<ol type="1">
<li>Every time we open the website, it will first spend a long time
creating index (faiss index) on ANN mode</li>
<li>Every time we query text by image, the GPU memory will increase
until it causes OOM error</li>
<li>Sometimes we upload an image on the website, the image will rotate
upsidedown automatically</li>
</ol>
<h2 id="streamlit-cache">Streamlit Cache</h2>
<p>When ANN begins, it will first create index for the whole database
and this always costs a very long time. Even I change some options,
streamlit UI will create the index again. This can obviously upset
users.</p>
<p>I learn from the Internet that streamlit has cache to stage important
data and do not need to reload them again and again.</p>
<p>At first, I wrap the create index function in a function and
descripted by <code>@st.cache(allow_output_mutation=True)</code>. But
the problem is not solved. The page will still create index.</p>
<p>Later I realize that I should cache the offline data rather that the
online creating process. So I use <code>faiss.write_index</code>
function to save the index on the disk and use
<code>faiss.read_index</code> function to load it.</p>
<p>This time the cache can stage these index and do not need to load
them frequently.</p>
<h2 id="oom-error">OOM error</h2>
<p>Every time we click the "generate" button to query text by image, the
GPU memory will increase around 180MB. What's more important is that,
the memory will not release unless we stop the streamlit process. This
drives me crazy because it means that I have to restart the service
usually.</p>
<p>The pipeline of this process is that:</p>
<ol type="1">
<li>Get the embedding vector of this image and move it to the designed
device (eg. GPU)</li>
<li>Load the text embeddings and move it to the designed device</li>
<li>Get the most similar text embedding with this image vector and
return</li>
</ol>
<p>At first, I believe that it is the movement of embeddings from CPU to
GPU causes this problem. So I try to let them stay on CPU and finish KNN
calculation. But this results in longer computing time.</p>
<p>I also try to use <code>torch.cuda.empty_cache()</code> and delete
embedding vectors after finish the calculation. But the problem is still
there.</p>
<p>Later, I use pdb to debug the program and find that when the image
vector is generated and moved to GPU, the memory has already increased.
The image2vector function is shown below.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">image2vector</span>(<span class="params">model, image</span>):</span><br><span class="line">    image_feature = model.encode_image(</span><br><span class="line">        preprocess(image).clone().detach().to(device).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    ).<span class="built_in">float</span>()</span><br><span class="line">    <span class="keyword">return</span> image_feature</span><br></pre></td></tr></table></figure>
<p>I search from the Internet and find that if the tensor has gradients,
it will not automatically release. So I add
<code>@torch.no_grad()</code> before the function and finally solve the
problem.</p>
<p>This time when GPU process an image, it will only use a fixed number
of memory (create for the first time). This system can run normally
forever.</p>
<h2 id="image-exif">Image EXIF</h2>
<p>We find that some uploaded images rotate upside-down automatically.
We later find that these images have EXIF (Exchangeable Image File
Format) with rotation value equals to 3 which means that they are
upside-down when they are taken.</p>
<p>We use the <code>ImageOps.exif_transpose</code> function in the
<code>PIL</code> package to solve the problem.</p>
<h1 id="project-management">Project Management</h1>
<p>I am the leader of this team. My teammates are Jo-Hua Wu, Yu-Ruei
Chang and Yi-An Chen.</p>
<p><img src="image-20221217203829472.png" style="zoom:25%;" /></p>
<p>To be honest, working with them is a pleasure for me. I feel happy
and released after the project. But I also want to list some
difficulties when I was leading this team.</p>
<p>The first problem is that we meet weekly on Tuesday and I cannot
really connect to my teammates and push the process on the other time.
We form a chat group both on WeChat and Line. But they chat less and do
not have a quick response in the group except for one person. I think if
for the next cooperation, I should make a week plan to give everyone the
direction of our group. And apart from weekly meeting in person, we can
also have online meetings sometimes to check the process of
everyone.</p>
<p>The second problem is that our workload is not very balanced. Wu's
and my work is more than others. I think this is not very fair for the
whole team. I am not complaining about my overload. I think I should
take this responsibility. But for the next time, I should not do every
thing by myself. I should not be a manager and a worker. As the leader,
I should be a supporter and a guider for my teammates to finish the task
together. Maybe I can start the program early and teach others how to
continue the work.</p>
<p>The last problem is that we have no review process. Everyone just
finish his/her work and don't know what others have done. This is
terrible because we cannot learn knowledge on others' parts. I think we
can have some sharing time on the meeting for everyone's work in the
next time.</p>
<p>All in all, this cooperation is pleasant and can be better. I will
continue to improve my leadership skills.</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="http://yaohaizhou.com">Yaohai Zhou</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yaohaizhou.com/2022/12/17/Vectorized-Similarity-Search-in-Multi-modal-Databases/">http://yaohaizhou.com/2022/12/17/Vectorized-Similarity-Search-in-Multi-modal-Databases/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Project/">Project</a></div><div class="post_share"><div class="social-share" data-image="/2022/12/17/Vectorized-Similarity-Search-in-Multi-modal-Databases/db.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-full"><a href="/2023/01/05/Cpp-Concurrency-in-Action-Note/"><img class="prev-cover" src="/2023/01/05/Cpp-Concurrency-in-Action-Note/CCIA.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">Cpp Concurrency in Action Note</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.JPG" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Yaohai Zhou</div><div class="author-info__description">Yaohai is a M.S. candidate with over 4 years of programming experience in various areas, including backend development, cloud & distributed systems, database and machine learning; solid programming skills in Go, Python, C++, and SQL; hands-on experience with Gin, PyTorch and GCP; strong knowledge of algorithms, data structures.</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">6</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/zyhhhy"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/zyhhhy" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:zyh828482@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Yaohai is a M.S. candidate with over 4 years of programming experience in various areas, including backend development, cloud computing, and machine learning; solid programming skills in Python, C++, Go, Java and SQL; hands-on experience with Gin, PyTorch and GCP; strong knowledge of algorithms, data structures.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#introduction"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#project-technology"><span class="toc-number">2.</span> <span class="toc-text">Project Technology</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#feature-embedding"><span class="toc-number">2.1.</span> <span class="toc-text">Feature Embedding</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#similarity-search"><span class="toc-number">2.2.</span> <span class="toc-text">Similarity Search</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#user-interface"><span class="toc-number">2.3.</span> <span class="toc-text">User Interface</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#implementation-details"><span class="toc-number">3.</span> <span class="toc-text">Implementation Details</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#streamlit-cache"><span class="toc-number">3.1.</span> <span class="toc-text">Streamlit Cache</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#oom-error"><span class="toc-number">3.2.</span> <span class="toc-text">OOM error</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#image-exif"><span class="toc-number">3.3.</span> <span class="toc-text">Image EXIF</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#project-management"><span class="toc-number">4.</span> <span class="toc-text">Project Management</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/09/29/Garbage-Collection-in-Golang/" title="Garbage Collection in Golang"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Garbage Collection in Golang"/></a><div class="content"><a class="title" href="/2023/09/29/Garbage-Collection-in-Golang/" title="Garbage Collection in Golang">Garbage Collection in Golang</a><time datetime="2023-09-30T06:14:17.000Z" title="Created 2023-09-29 23:14:17">2023-09-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/08/13/Looking-Back-On-The-Past-Three-Years/" title="Looking Back On The Past Three Years"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Looking Back On The Past Three Years"/></a><div class="content"><a class="title" href="/2023/08/13/Looking-Back-On-The-Past-Three-Years/" title="Looking Back On The Past Three Years">Looking Back On The Past Three Years</a><time datetime="2023-08-14T03:49:26.000Z" title="Created 2023-08-13 20:49:26">2023-08-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/21/About-Me/" title="About Me"><img src="/2023/03/21/About-Me/aboutme.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="About Me"/></a><div class="content"><a class="title" href="/2023/03/21/About-Me/" title="About Me">About Me</a><time datetime="2023-03-22T06:14:58.000Z" title="Created 2023-03-21 23:14:58">2023-03-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/01/17/Distributed-Systems-MIT6-824-Notes/" title="Distributed Systems MIT6.824 Notes"><img src="/2023/01/17/Distributed-Systems-MIT6-824-Notes/gfs.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Distributed Systems MIT6.824 Notes"/></a><div class="content"><a class="title" href="/2023/01/17/Distributed-Systems-MIT6-824-Notes/" title="Distributed Systems MIT6.824 Notes">Distributed Systems MIT6.824 Notes</a><time datetime="2023-01-17T23:22:11.000Z" title="Created 2023-01-17 15:22:11">2023-01-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/01/05/Cpp-Concurrency-in-Action-Note/" title="Cpp Concurrency in Action Note"><img src="/2023/01/05/Cpp-Concurrency-in-Action-Note/CCIA.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Cpp Concurrency in Action Note"/></a><div class="content"><a class="title" href="/2023/01/05/Cpp-Concurrency-in-Action-Note/" title="Cpp Concurrency in Action Note">Cpp Concurrency in Action Note</a><time datetime="2023-01-06T00:43:08.000Z" title="Created 2023-01-05 16:43:08">2023-01-05</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Yaohai Zhou</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>